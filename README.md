# Bright News
Web app that analyses the positivity of a news site. Made with a React frontend and a Django backend. Link to live site: https://mihailthebuilder.github.io/bright-news-web-frontend/

**Note**: The front-end sits on a different repo, see [this](#architecture) for more. The scoring algorithm hasn't been designed (or tested) for sites that either aren't in English, or aren't focused on providing news content.

# Table of contents
- [Bright News](#bright-news)
- [Table of contents](#table-of-contents)
- [Front-end](#front-end)
  - [Architecture](#architecture)
  - [Pages](#pages)
  - [Running the Analysis](#running-the-analysis)
  - [Mobile responsive](#mobile-responsive)
- [Back-end](#back-end)
  - [Architecture](#architecture-1)
  - [Views](#views)
  - [Models](#models)
  - [Scoring process](#scoring-process)
    - [Fetching the raw data](#fetching-the-raw-data)
    - [Data cleansing](#data-cleansing)
    - [Absolute scoring](#absolute-scoring)

# Front-end

## Architecture

The front-end is a React SPA that sits on a [different repo](https://github.com/mihailthebuilder/bright-news-web-frontend) and is hosted with GitHub Pages. 

I decided to keep it separate from the back-end because I felt it would create unnecessary complexity. Django pushes a server-side rendering approach, with HTML components delivered independently one of the other. This is more ideal for sites that deliver a lot of content.

However, the client-side is very light on content that's not generated by the scoring algorithm. I also have completely different sections in the HTML interacting with each other.

## Pages

The SPA is made up of 3 "pages": 
- Landing - simple page where you input the website you wish to analyse
- Results - shows the results of the analysis
- About - explains this project

The same URL is being used across all 3; the `page` state in `App.js` decides which page to show. I did consider using [React Router](https://reactrouter.com/) in order to have the URL appropriate reflect the page. The downside was that I would've had to build rules for when someone directly accesses the Results page URL.

The `Footer` component is reused across the 3 pages in exactly the same shape. The header (`NavBar`) component is also reused, but with a twist: when the user goes to the Results or About pages, a smaller search bar will be sent to `NavBar` as a child component. This search bar is another instance of the same `SearchBar` component as the one on the Landing page.

## Running the Analysis
After you input the site's URL and click the Analyse button, the `getUrlResults` function gets triggered. The function first sets the `loadingSearch` state to `true` in order to show a loading spinner on the button. It then calls the backend API using [axios](https://www.npmjs.com/package/axios) to retrieve the results. 2 things can happen afterwards:
1. If the results are invalid, an error message is shown for 3 seconds via the `ErrorMessage` component.
2. If the results are valid, you get shown the Results page with the data fetched from the API.

You may notice that I do a ton of data manipulation in the components for the Results page - `ResultsDetails`, `ScoreGroup` and `ScoreDetails`. You might then wonder why I don't do it on the backend; Python would be amazing for that right? The reason - I wanted to reduce latency, as well as the computational burden since I'm on a free Heroku tier ðŸ˜…

## Mobile responsive

Wouldn't have it any other way ðŸ“±ðŸ”¥

![mobile responsive](demo/mobile-responsive.gif)

# Back-end

## Architecture

The back-end is a Django RESTful API hosted on Heroku's free tier. It's completely separate from the front-end and the codebase sits in this repo. 

## Views

There's only 1 view in this Django project and it corresponds to the API endpoint that connects to the front-end. It receives the URL of the news site and returns the analysis data. I leverage [Django REST framework](https://www.django-rest-framework.org/) to set up this view using the generic `APIView` class.

## Models
2 models that database all the site submissions together with the data generated from my analysis:
1. `WebsiteModel` - sites that were successfully analysed
2. `FailedWebsiteModel` - sites where the back-end couldn't successfully send analysis results back to the front-end

This enables me to see all the data in my Django admin panel and discover gems ðŸ˜„
![models](demo/models.png)

## Scoring process

### Fetching the raw data

The scoring process starts by going to the URL that has been sent to the API. Upon successful entry, it uses [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) to fetch all the text and splits it into a `list` according to their HTML elements. 

### Data cleansing

I remove any text piece that meets any of the following criteria:
- Includes site-generic terms such as "cookie" or "sign up".
- Doesn't have enough words; the sentiment model struggles to analyse them.
- Are duplicates

I also apply some encoding/decoding black magic using the `text_transform` function to remove odd characters.

### Absolute scoring

I selected the [VADER](https://github.com/cjhutto/vaderSentiment) and [AFINN](https://github.com/fnielsen/afinn) sentiment analysis libraries for generating my site positivity scores. Both are well-known in the NLP space. I tested them on a few samples as well; they seem to be quite reliable and complementary of each other.

I go through each piece of text and compare the scores generated by the two libraries. The aggregate score is based on several situations:
1. Both scores are of the same sign -> aggregate score is +1.
2. One score is 0 while another is non-0 -> aggregate score is +/-1 depending on the sign of the score.
3. The two scores are of opposite signs -> aggregate score is 0 because the models seem unreliable.
4. The two scores are 0 -> aggregate score is again 0.

You'll notice I convert all scores to +/-1 and 0; using the actual magnitudes didn't produce reliable results for me.

Finally, I calculate the entire site's **absolute** score by dividing the number of (+1) text pieces by the number of non-0 text pieces. But we're not done yet :)

