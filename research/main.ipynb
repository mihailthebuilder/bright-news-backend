{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules from web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os.path\n",
    "\n",
    "modules_dir = os.path.join(os.path.abspath(''),\"..\") + \"/main/modules\"\n",
    "sys.path.append(modules_dir)\n",
    "\n",
    "import scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve HTML text from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = scraping.request(\"bbc.co.uk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the request was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<!DOCTYPE html><html lang=\"en-GB\" class=\"no-js\"><head><meta charSet=\"utf-8\" /><meta name=\"viewport\" \n"
     ]
    }
   ],
   "source": [
    "print(response.status_code)\n",
    "print(response.text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the HTML content as a string to analyse. In order for people to replicate my results, I've already downloaded the HTML text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response_text = response.text\n",
    "#with open(\"response.txt\", \"w\") as text_file:\n",
    "#    text_file.write(response_text)\n",
    "\n",
    "with open(\"response.txt\",\"r\") as text_file:\n",
    "    response_text = text_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the HTML text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = scraping.process(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "['One mystery, four suspects, many lies. iPlayer', 'Olympian Adam Peaty joins the all-star Strictly 2021 line-up', \"Teachers: 'It's been hell grading exams'\", \"Gunman's victims include three-year-old girl\", \"Why the Tourette's queen of Twitch hasn't been banned\", 'Superstar violinist Nicola Benedetti delights the Proms. IPlayer-Video', 'York & North Yorkshire', \"'When you're on a BMX 20 feet in the air there's no room for error' Video\", \"Britney Spears' father to step down as conservator\", 'England bat after Anderson takes five wickets in second Test']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(tokens[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score each of the tokens using...\n",
    "- [AFINN](https://github.com/fnielsen/afinn) = wordlist-based approach\n",
    "- [VADER](https://github.com/cjhutto/vaderSentiment) = lexicon+rule-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "afinn = Afinn()\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "scored_tokens = []\n",
    "\n",
    "for token in tokens:\n",
    "  # afinn.score calculates by adding up individual scores for words\n",
    "  # so you need to standardise by dividing the length of the phrase\n",
    "  afinn_score = afinn.score(token) / len(token.split())\n",
    "\n",
    "  vader_score = vader.polarity_scores(token)[\"compound\"]\n",
    "  \n",
    "  scored_tokens.append({\"token\": token, \"afinn_score\": afinn_score, \"vader_score\": vader_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 [{'token': 'One mystery, four suspects, many lies. iPlayer', 'afinn_score': -0.14285714285714285, 'vader_score': -0.6369}, {'token': 'Olympian Adam Peaty joins the all-star Strictly 2021 line-up', 'afinn_score': 0.0, 'vader_score': 0.0}, {'token': \"Teachers: 'It's been hell grading exams'\", 'afinn_score': -0.6666666666666666, 'vader_score': -0.6808}, {'token': \"Gunman's victims include three-year-old girl\", 'afinn_score': -0.6, 'vader_score': -0.3182}, {'token': \"Why the Tourette's queen of Twitch hasn't been banned\", 'afinn_score': -0.2222222222222222, 'vader_score': 0.357}, {'token': 'Superstar violinist Nicola Benedetti delights the Proms. IPlayer-Video', 'afinn_score': 0.375, 'vader_score': 0.4588}, {'token': 'York & North Yorkshire', 'afinn_score': 0.0, 'vader_score': 0.0}, {'token': \"'When you're on a BMX 20 feet in the air there's no room for error' Video\", 'afinn_score': -0.1875, 'vader_score': -0.5994}, {'token': \"Britney Spears' father to step down as conservator\", 'afinn_score': 0.0, 'vader_score': 0.0}, {'token': 'England bat after Anderson takes five wickets in second Test', 'afinn_score': 0.0, 'vader_score': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "print(len(scored_tokens), scored_tokens[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's export a slice of the data in an Excel file so we can spot-check the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"max_row\",None)\n",
    "\n",
    "token_df = pd.DataFrame(scored_tokens)\n",
    "\n",
    "token_df.iloc[33:43].to_csv(\"out.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both scoring models seem pretty accurate and mostly agree with each other. The few exceptions:\n",
    "- `Composer, DJ and bandleader...` should be a positive text, yet both models scored it as neutral. I can see why though, there weren't any particular words that suggested positivity.\n",
    "- `Totally affordable...` was missed out by VADER as being a positive word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see all the places where the two models disagree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_token = token_df[(token_df[\"afinn_score\"] * token_df[\"vader_score\"] <= 0) &\n",
    "    ((token_df[\"afinn_score\"] != 0) | (token_df[\"vader_score\"] != 0))]\n",
    "\n",
    "filtered_token.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there's 14 out of 79 places where the 2 models disagree, which is roughly 25% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look where exactly there's disagreements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15314/1137237511.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_colwidth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiltered_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_token' is not defined"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "filtered_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AFINN got 6 right, while VADER got the remainder 8. There's no clear winner then. What if we now look into this using a trained, state-of-the-art model? Enter HuggingFace.\n",
    "\n",
    "We have several options on the menu: classic BERT, DistilBERT, RoBERTa and XLNet. I'm choosing DistilBERT because it's the most resource-light - this is a side project, after all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34e04979d73b2ceef69adabefb5e026b4557b5b2bae59a0151ac0f9ce1842be6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
